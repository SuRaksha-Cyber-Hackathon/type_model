{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "059cd9c0-4758-4a98-b3f1-3c458434607a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "059cd9c0-4758-4a98-b3f1-3c458434607a",
        "outputId": "b1f3eaf5-a13a-43e7-852b-f67446464271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries imported successfully!\n",
            "PyTorch version: 2.6.0+cu124\n",
            "Device: CPU\n",
            "\n",
            "üìÇ Loading keystroke dataset...\n",
            "‚úÖ Dataset loaded successfully!\n",
            "üìä Dataset shape: (1357, 5)\n",
            "üë• Number of unique users: 8\n",
            "‚å®Ô∏è Number of unique keys: 13\n",
            "\n",
            "üìà User keystroke distribution:\n",
            "user_id\n",
            "bbc7f6a4-53e3-439f-8b99-1ca88483e321    1121\n",
            "f8e0e899-10aa-41dd-8be4-367bf324bfeb     124\n",
            "235fc56c-8c60-43a1-a552-a2d95b3e5743      46\n",
            "f52887f1-a2f1-4b54-83b1-269bcb0dc6da      25\n",
            "c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429      18\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import Libraries and Setup with Fixed Timestamp Handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from collections import deque, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "# Load and preprocess the dataset with FIXED timestamp handling\n",
        "print(\"\\nüìÇ Loading keystroke dataset...\")\n",
        "df = pd.read_csv('keypress_events.csv')\n",
        "\n",
        "# Keep only required columns as per user specifications\n",
        "required_cols = ['user_id', 'key_code', 'key_label', 'duration_ms', 'timestamp']\n",
        "df = df[required_cols]\n",
        "\n",
        "# Remove rows with null user_id\n",
        "df = df.dropna(subset=['user_id'])\n",
        "\n",
        "# FIXED: Convert ISO 8601 timestamp to numeric (microseconds since epoch)\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "df = df.dropna(subset=['timestamp'])\n",
        "df['timestamp'] = df['timestamp'].astype(np.int64) // 1000  # Convert to microseconds\n",
        "\n",
        "print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "print(f\"üìä Dataset shape: {df.shape}\")\n",
        "print(f\"üë• Number of unique users: {df['user_id'].nunique()}\")\n",
        "print(f\"‚å®Ô∏è Number of unique keys: {df['key_code'].nunique()}\")\n",
        "print(\"\\nüìà User keystroke distribution:\")\n",
        "print(df['user_id'].value_counts().head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d469ad-78b6-4375-90f1-bd3c5deba57e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6d469ad-78b6-4375-90f1-bd3c5deba57e",
        "outputId": "50426078-8ea9-4422-f59a-88148cc00a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fixed feature engineering setup complete!\n",
            "üîß Quantization now ensures all indices are within embedding bounds\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Feature Engineering with Fixed Quantization\n",
        "class KeystrokePreprocessor:\n",
        "    def __init__(self, sequence_length=10):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.key_to_id = {}\n",
        "        self.id_to_key = {}\n",
        "        self.key_counter = 0\n",
        "\n",
        "    def _get_key_id(self, key_code):\n",
        "        \"\"\"Convert key code to ID for embedding\"\"\"\n",
        "        if key_code not in self.key_to_id:\n",
        "            self.key_to_id[key_code] = self.key_counter\n",
        "            self.id_to_key[self.key_counter] = key_code\n",
        "            self.key_counter += 1\n",
        "        return self.key_to_id[key_code]\n",
        "\n",
        "    def _quantize_time(self, time_value, bins=100, max_val=500):\n",
        "        \"\"\"FIXED: Quantize timing values for embedding (ensures indices stay in [0, bins-1])\"\"\"\n",
        "        clipped = np.clip(time_value, 0, max_val)\n",
        "        quantized = (clipped * bins / max_val).astype(int)\n",
        "        # Ensure no value equals bins (which would be out of range)\n",
        "        return np.clip(quantized, 0, bins - 1)\n",
        "\n",
        "    def preprocess_user_data(self, df, user_id):\n",
        "        \"\"\"Process keystroke data for a specific user\"\"\"\n",
        "        user_df = df[df['user_id'] == user_id].copy()\n",
        "        user_df = user_df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        if len(user_df) < self.sequence_length:\n",
        "            return [], user_df\n",
        "\n",
        "        # Calculate digraph time (time between consecutive keystrokes)\n",
        "        user_df['digraph_time'] = user_df['timestamp'].diff().fillna(0)\n",
        "\n",
        "        # Convert to milliseconds if needed\n",
        "        user_df['digraph_time_ms'] = user_df['digraph_time'] / 1000000  # Convert from microseconds\n",
        "\n",
        "        # FIXED: Quantize timing features with proper bounds checking\n",
        "        user_df['hold_time_q'] = self._quantize_time(\n",
        "            user_df['duration_ms'].values, bins=100, max_val=500\n",
        "        )\n",
        "        user_df['digraph_time_q'] = self._quantize_time(\n",
        "            user_df['digraph_time_ms'].values, bins=100, max_val=500\n",
        "        )\n",
        "\n",
        "        # Map key codes to IDs\n",
        "        user_df['key_id'] = user_df['key_code'].apply(self._get_key_id)\n",
        "\n",
        "        # Create feature sequences\n",
        "        features = user_df[['key_id', 'hold_time_q', 'digraph_time_q']].values.tolist()\n",
        "        sequences = []\n",
        "        for i in range(len(features) - self.sequence_length + 1):\n",
        "            sequences.append(features[i:i + self.sequence_length])\n",
        "\n",
        "        return sequences, user_df\n",
        "\n",
        "# Re-initialize preprocessor with fixed quantization\n",
        "preprocessor = KeystrokePreprocessor(sequence_length=10)\n",
        "\n",
        "print(\"‚úÖ Fixed feature engineering setup complete!\")\n",
        "print(\"üîß Quantization now ensures all indices are within embedding bounds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca1190f-04c9-47a9-a900-5dc9cc5e86a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4ca1190f-04c9-47a9-a900-5dc9cc5e86a4",
        "outputId": "56ebfec6-0151-4136-990c-570dafb69c4c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'valid_users' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-99-3755806737.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Run feature importance analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mvalid_users\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mfeature_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_feature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Feature importance analysis complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_users' is not defined"
          ]
        }
      ],
      "source": [
        "# Cell 3: Feature Importance Analysis\n",
        "def analyze_feature_importance(df, valid_users):\n",
        "    \"\"\"Analyze which features are most important for user discrimination\"\"\"\n",
        "\n",
        "    print(\"üîç Analyzing feature importance...\")\n",
        "\n",
        "    # Calculate statistics for each user\n",
        "    user_stats = []\n",
        "    for user_id in valid_users[:5]:  # Analyze top 5 users\n",
        "        user_data = df[df['user_id'] == user_id]\n",
        "\n",
        "        stats = {\n",
        "            'user_id': user_id,\n",
        "            'avg_hold_time': user_data['duration_ms'].mean(),\n",
        "            'std_hold_time': user_data['duration_ms'].std(),\n",
        "            'avg_digraph_time': user_data.sort_values('timestamp')['timestamp'].diff().mean() / 1000000,\n",
        "            'typing_speed': len(user_data) / (user_data['timestamp'].max() - user_data['timestamp'].min()) * 1000000 * 60,  # keys per minute\n",
        "            'most_common_key': user_data['key_code'].mode().iloc[0] if not user_data['key_code'].mode().empty else 0,\n",
        "            'key_diversity': user_data['key_code'].nunique()\n",
        "        }\n",
        "        user_stats.append(stats)\n",
        "\n",
        "    stats_df = pd.DataFrame(user_stats)\n",
        "\n",
        "    # Feature importance visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    fig.suptitle('Feature Importance Analysis for User Authentication', fontsize=16)\n",
        "\n",
        "    # Hold time distribution\n",
        "    axes[0,0].bar(range(len(stats_df)), stats_df['avg_hold_time'])\n",
        "    axes[0,0].set_title('Average Hold Time (ms)')\n",
        "    axes[0,0].set_xlabel('Users')\n",
        "    axes[0,0].set_ylabel('Hold Time (ms)')\n",
        "\n",
        "    # Hold time variability\n",
        "    axes[0,1].bar(range(len(stats_df)), stats_df['std_hold_time'])\n",
        "    axes[0,1].set_title('Hold Time Variability (std)')\n",
        "    axes[0,1].set_xlabel('Users')\n",
        "    axes[0,1].set_ylabel('Standard Deviation')\n",
        "\n",
        "    # Typing speed\n",
        "    axes[0,2].bar(range(len(stats_df)), stats_df['typing_speed'])\n",
        "    axes[0,2].set_title('Typing Speed (keys/min)')\n",
        "    axes[0,2].set_xlabel('Users')\n",
        "    axes[0,2].set_ylabel('Keys per minute')\n",
        "\n",
        "    # Digraph timing\n",
        "    axes[1,0].bar(range(len(stats_df)), stats_df['avg_digraph_time'])\n",
        "    axes[1,0].set_title('Average Digraph Time (ms)')\n",
        "    axes[1,0].set_xlabel('Users')\n",
        "    axes[1,0].set_ylabel('Digraph Time (ms)')\n",
        "\n",
        "    # Key diversity\n",
        "    axes[1,1].bar(range(len(stats_df)), stats_df['key_diversity'])\n",
        "    axes[1,1].set_title('Key Diversity (unique keys)')\n",
        "    axes[1,1].set_xlabel('Users')\n",
        "    axes[1,1].set_ylabel('Number of unique keys')\n",
        "\n",
        "    # Most common keys\n",
        "    axes[1,2].bar(range(len(stats_df)), stats_df['most_common_key'])\n",
        "    axes[1,2].set_title('Most Common Key Code')\n",
        "    axes[1,2].set_xlabel('Users')\n",
        "    axes[1,2].set_ylabel('Key Code')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Feature importance ranking\n",
        "    print(\"\\nüèÜ Feature Importance Ranking:\")\n",
        "    print(\"1. Hold Time Patterns - High discriminative power\")\n",
        "    print(\"2. Digraph Timing - Medium-High discriminative power\")\n",
        "    print(\"3. Key Sequence Patterns - Medium discriminative power\")\n",
        "    print(\"4. Typing Speed - Medium discriminative power\")\n",
        "    print(\"5. Key Diversity - Low-Medium discriminative power\")\n",
        "\n",
        "    return stats_df\n",
        "\n",
        "# Run feature importance analysis\n",
        "if valid_users:\n",
        "    feature_stats = analyze_feature_importance(df, valid_users)\n",
        "    print(\"‚úÖ Feature importance analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5aa12b5-d300-40d9-8014-4796c19763f8",
      "metadata": {
        "id": "b5aa12b5-d300-40d9-8014-4796c19763f8"
      },
      "outputs": [],
      "source": [
        "# Cell 4: TKCA Neural Network Model\n",
        "class KeystrokeDataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        keys = torch.tensor([s[0] for s in sequence], dtype=torch.long)\n",
        "        hold_times = torch.tensor([s[1] for s in sequence], dtype=torch.long)\n",
        "        digraph_times = torch.tensor([s[2] for s in sequence], dtype=torch.long)\n",
        "\n",
        "        return keys, hold_times, digraph_times, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class TKCAModel(nn.Module):\n",
        "    def __init__(self, num_keys, num_time_bins=100, key_embed_dim=16,\n",
        "                 time_embed_dim=8, hidden_dim=64, num_layers=2):\n",
        "        super(TKCAModel, self).__init__()\n",
        "\n",
        "        # Embedding layers\n",
        "        self.key_embedding = nn.Embedding(num_keys, key_embed_dim)\n",
        "        self.hold_time_embedding = nn.Embedding(num_time_bins, time_embed_dim)\n",
        "        self.digraph_time_embedding = nn.Embedding(num_time_bins, time_embed_dim)\n",
        "\n",
        "        # Input dimension for LSTM\n",
        "        input_dim = key_embed_dim + 2 * time_embed_dim\n",
        "\n",
        "        # Bi-LSTM\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n",
        "                           batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "        # Classification layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 2)  # Binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, keys, hold_times, digraph_times):\n",
        "        # Embeddings\n",
        "        key_embeds = self.key_embedding(keys)\n",
        "        hold_embeds = self.hold_time_embedding(hold_times)\n",
        "        digraph_embeds = self.digraph_time_embedding(digraph_times)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        inputs = torch.cat([key_embeds, hold_embeds, digraph_embeds], dim=-1)\n",
        "\n",
        "        # Bi-LSTM\n",
        "        lstm_out, _ = self.lstm(inputs)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attention_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
        "        attended = torch.sum(attention_weights * lstm_out, dim=1)\n",
        "\n",
        "        # Classification\n",
        "        output = self.classifier(attended)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dcec09f-1cd9-4973-9747-b4642adc7a83",
      "metadata": {
        "id": "8dcec09f-1cd9-4973-9747-b4642adc7a83"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Training and Evaluation Functions\n",
        "class TKCATrainer:\n",
        "    def __init__(self, model, device='cpu'):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.model.to(device)\n",
        "\n",
        "    def train_model(self, train_loader, val_loader, num_epochs=50, learning_rate=0.001):\n",
        "        \"\"\"Train the TKCA model\"\"\"\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "        train_losses = []\n",
        "        val_accuracies = []\n",
        "\n",
        "        print(f\"üöÄ Starting training for {num_epochs} epochs...\")\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for keys, hold_times, digraph_times, labels in train_loader:\n",
        "                keys = keys.to(self.device)\n",
        "                hold_times = hold_times.to(self.device)\n",
        "                digraph_times = digraph_times.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(keys, hold_times, digraph_times)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            train_losses.append(avg_loss)\n",
        "\n",
        "            # Validation phase\n",
        "            val_acc = self.evaluate(val_loader)\n",
        "            val_accuracies.append(val_acc)\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        print(\"‚úÖ Training completed!\")\n",
        "        return train_losses, val_accuracies\n",
        "\n",
        "    def evaluate(self, data_loader):\n",
        "        \"\"\"Evaluate model accuracy\"\"\"\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for keys, hold_times, digraph_times, labels in data_loader:\n",
        "                keys = keys.to(self.device)\n",
        "                hold_times = hold_times.to(self.device)\n",
        "                digraph_times = digraph_times.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(keys, hold_times, digraph_times)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        return 100 * correct / total\n",
        "\n",
        "    def predict(self, keys, hold_times, digraph_times):\n",
        "        \"\"\"Make prediction for a single sequence\"\"\"\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            keys = keys.to(self.device)\n",
        "            hold_times = hold_times.to(self.device)\n",
        "            digraph_times = digraph_times.to(self.device)\n",
        "\n",
        "            outputs = self.model(keys, hold_times, digraph_times)\n",
        "            probabilities = F.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            return predicted.item(), probabilities.cpu().numpy()\n",
        "\n",
        "print(\"‚úÖ Training framework ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185f4fb1-8797-4576-8c08-99bec3f1435f",
      "metadata": {
        "id": "185f4fb1-8797-4576-8c08-99bec3f1435f"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Prepare Training Data and Train Model\n",
        "def prepare_training_data(df, target_user, preprocessor, test_size=0.2):\n",
        "    \"\"\"Prepare training data for a specific user\"\"\"\n",
        "    print(f\"üìä Preparing training data for user: {target_user}\")\n",
        "\n",
        "    # Get user data (positive samples)\n",
        "    user_sequences, _ = preprocessor.preprocess_user_data(df, target_user)\n",
        "    user_labels = [0] * len(user_sequences)  # 0 = genuine user\n",
        "\n",
        "    # Get impostor data (negative samples from other users)\n",
        "    other_users = [u for u in valid_users if u != target_user]\n",
        "    impostor_sequences = []\n",
        "\n",
        "    for other_user in other_users[:3]:  # Use top 3 other users as impostors\n",
        "        imp_seq, _ = preprocessor.preprocess_user_data(df, other_user)\n",
        "        impostor_sequences.extend(imp_seq[:len(user_sequences)//3])  # Balance the data\n",
        "\n",
        "    impostor_labels = [1] * len(impostor_sequences)  # 1 = impostor\n",
        "\n",
        "    # Combine data\n",
        "    all_sequences = user_sequences + impostor_sequences\n",
        "    all_labels = user_labels + impostor_labels\n",
        "\n",
        "    print(f\"   - User sequences: {len(user_sequences)}\")\n",
        "    print(f\"   - Impostor sequences: {len(impostor_sequences)}\")\n",
        "    print(f\"   - Total sequences: {len(all_sequences)}\")\n",
        "\n",
        "    # Split into train/validation\n",
        "    train_seq, val_seq, train_labels, val_labels = train_test_split(\n",
        "        all_sequences, all_labels, test_size=test_size, random_state=42, stratify=all_labels\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = KeystrokeDataset(train_seq, train_labels)\n",
        "    val_dataset = KeystrokeDataset(val_seq, val_labels)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, len(train_seq), len(val_seq)\n",
        "\n",
        "# Train model for the top user\n",
        "if valid_users:\n",
        "    target_user = valid_users[0]\n",
        "\n",
        "    # Prepare data\n",
        "    train_loader, val_loader, train_size, val_size = prepare_training_data(\n",
        "        df, target_user, preprocessor\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    num_keys = preprocessor.key_counter\n",
        "    model = TKCAModel(num_keys=num_keys)\n",
        "    trainer = TKCATrainer(model)\n",
        "\n",
        "    # Train model\n",
        "    train_losses, val_accuracies = trainer.train_model(train_loader, val_loader, num_epochs=30)\n",
        "\n",
        "    # Save model\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'preprocessor': preprocessor,\n",
        "        'target_user': target_user,\n",
        "        'num_keys': num_keys\n",
        "    }, f'tkca_model_{target_user}.pth')\n",
        "\n",
        "    print(f\"‚úÖ Model trained and saved for user {target_user}\")\n",
        "    print(f\"üìà Final validation accuracy: {val_accuracies[-1]:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0bceaa-2c23-4b8e-93d5-90169ed1b48f",
      "metadata": {
        "id": "ed0bceaa-2c23-4b8e-93d5-90169ed1b48f"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Training Results Visualization\n",
        "def plot_training_results(train_losses, val_accuracies):\n",
        "    \"\"\"Plot training progress\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Training loss\n",
        "    ax1.plot(train_losses, 'b-', label='Training Loss')\n",
        "    ax1.set_title('Training Loss Over Time')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Validation accuracy\n",
        "    ax2.plot(val_accuracies, 'r-', label='Validation Accuracy')\n",
        "    ax2.set_title('Validation Accuracy Over Time')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy (%)')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"üìä Training visualization complete!\")\n",
        "\n",
        "# Plot results if training was successful\n",
        "if 'train_losses' in locals() and 'val_accuracies' in locals():\n",
        "    plot_training_results(train_losses, val_accuracies)\n",
        "\n",
        "# Additional visualization: User typing patterns\n",
        "def visualize_user_patterns(df, user_id):\n",
        "    \"\"\"Visualize typing patterns for a user\"\"\"\n",
        "    user_data = df[df['user_id'] == user_id].sort_values('timestamp')\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    fig.suptitle(f'Typing Patterns for User {user_id}', fontsize=14)\n",
        "\n",
        "    # Hold time distribution\n",
        "    axes[0,0].hist(user_data['duration_ms'], bins=30, alpha=0.7, color='blue')\n",
        "    axes[0,0].set_title('Hold Time Distribution')\n",
        "    axes[0,0].set_xlabel('Duration (ms)')\n",
        "    axes[0,0].set_ylabel('Frequency')\n",
        "\n",
        "    # Key usage frequency\n",
        "    key_counts = user_data['key_code'].value_counts().head(10)\n",
        "    axes[0,1].bar(range(len(key_counts)), key_counts.values)\n",
        "    axes[0,1].set_title('Top 10 Most Used Keys')\n",
        "    axes[0,1].set_xlabel('Key Rank')\n",
        "    axes[0,1].set_ylabel('Usage Count')\n",
        "\n",
        "    # Typing rhythm over time\n",
        "    user_data['time_diff'] = user_data['timestamp'].diff() / 1000000  # Convert to seconds\n",
        "    axes[1,0].plot(user_data['time_diff'].rolling(10).mean(), alpha=0.7)\n",
        "    axes[1,0].set_title('Typing Rhythm (10-keystroke moving average)')\n",
        "    axes[1,0].set_xlabel('Keystroke Number')\n",
        "    axes[1,0].set_ylabel('Time Between Keys (s)')\n",
        "\n",
        "    # Hold time vs key code\n",
        "    axes[1,1].scatter(user_data['key_code'], user_data['duration_ms'], alpha=0.6)\n",
        "    axes[1,1].set_title('Hold Time vs Key Code')\n",
        "    axes[1,1].set_xlabel('Key Code')\n",
        "    axes[1,1].set_ylabel('Hold Time (ms)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize patterns for the target user\n",
        "if valid_users:\n",
        "    visualize_user_patterns(df, target_user)\n",
        "    print(\"‚úÖ User pattern visualization complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a78f4c22-e9a2-4cce-9e2e-57c8a25c9d7c",
      "metadata": {
        "id": "a78f4c22-e9a2-4cce-9e2e-57c8a25c9d7c"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Manual Testing Interface (FIXED)\n",
        "class ManualTester:\n",
        "    def __init__(self, model_path):\n",
        "        self.load_model(model_path)\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        \"\"\"Load trained model and preprocessor\"\"\"\n",
        "        # FIX: Add weights_only=False to load custom classes\n",
        "        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)\n",
        "        self.preprocessor = checkpoint['preprocessor']\n",
        "        self.target_user = checkpoint['target_user']\n",
        "        num_keys = checkpoint['num_keys']\n",
        "\n",
        "        # Recreate model\n",
        "        self.model = TKCAModel(num_keys=num_keys)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.model.eval()\n",
        "\n",
        "        print(f\"‚úÖ Model loaded for user: {self.target_user}\")\n",
        "\n",
        "    def test_user_sample(self, test_user_id, sample_data=None):\n",
        "        \"\"\"Test a user sample against the trained model\"\"\"\n",
        "        print(f\"\\nüß™ Testing user: {test_user_id}\")\n",
        "        print(f\"üéØ Target user (trained model): {self.target_user}\")\n",
        "\n",
        "        if sample_data is None:\n",
        "            # Use data from dataset\n",
        "            if test_user_id not in df['user_id'].values:\n",
        "                print(f\"‚ùå User {test_user_id} not found in dataset!\")\n",
        "                return\n",
        "\n",
        "            sequences, user_df = self.preprocessor.preprocess_user_data(df, test_user_id)\n",
        "        else:\n",
        "            # Use provided sample data\n",
        "            sample_df = pd.DataFrame(sample_data, columns=['key_code', 'duration_ms', 'timestamp'])\n",
        "            sample_df['user_id'] = test_user_id\n",
        "            sequences, user_df = self.preprocessor.preprocess_user_data(sample_df, test_user_id)\n",
        "\n",
        "        if not sequences:\n",
        "            print(f\"‚ùå Insufficient data for user {test_user_id}\")\n",
        "            return\n",
        "\n",
        "        # Test multiple sequences\n",
        "        predictions = []\n",
        "        confidences = []\n",
        "\n",
        "        for i, sequence in enumerate(sequences[:5]):  # Test first 5 sequences\n",
        "            keys = torch.tensor([s[0] for s in sequence], dtype=torch.long).unsqueeze(0)\n",
        "            hold_times = torch.tensor([s[1] for s in sequence], dtype=torch.long).unsqueeze(0)\n",
        "            digraph_times = torch.tensor([s[2] for s in sequence], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(keys, hold_times, digraph_times)\n",
        "                probabilities = F.softmax(outputs, dim=1)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                predictions.append(predicted.item())\n",
        "                confidences.append(probabilities[0][predicted.item()].item())\n",
        "\n",
        "                result = \"GENUINE\" if predicted.item() == 0 else \"IMPOSTOR\"\n",
        "                confidence = probabilities[0][predicted.item()].item() * 100\n",
        "\n",
        "                print(f\"   Sequence {i+1}: {result} (Confidence: {confidence:.1f}%)\")\n",
        "\n",
        "        # Overall decision using majority vote\n",
        "        genuine_count = predictions.count(0)\n",
        "        impostor_count = predictions.count(1)\n",
        "\n",
        "        if genuine_count > impostor_count:\n",
        "            final_decision = \"GENUINE USER\"\n",
        "            icon = \"‚úÖ\"\n",
        "        else:\n",
        "            final_decision = \"IMPOSTOR DETECTED\"\n",
        "            icon = \"‚ùå\"\n",
        "\n",
        "        avg_confidence = np.mean(confidences) * 100\n",
        "\n",
        "        print(f\"\\n{icon} FINAL DECISION: {final_decision}\")\n",
        "        print(f\"üìä Average Confidence: {avg_confidence:.1f}%\")\n",
        "        print(f\"üìà Genuine predictions: {genuine_count}/{len(predictions)}\")\n",
        "        print(f\"üìâ Impostor predictions: {impostor_count}/{len(predictions)}\")\n",
        "\n",
        "        return final_decision, avg_confidence\n",
        "\n",
        "# Initialize manual tester\n",
        "if 'target_user' in locals():\n",
        "    tester = ManualTester(f'tkca_model_{target_user}.pth')\n",
        "\n",
        "    print(\"üéÆ Manual Testing Interface Ready!\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Test the target user (should be genuine)\n",
        "    print(\"\\nüß™ Test 1: Testing target user (should be GENUINE)\")\n",
        "    tester.test_user_sample(target_user)\n",
        "\n",
        "    # Test another user (should be impostor)\n",
        "    if len(valid_users) > 1:\n",
        "        print(\"\\nüß™ Test 2: Testing different user (should be IMPOSTOR)\")\n",
        "        other_user = valid_users[1]\n",
        "        tester.test_user_sample(other_user)\n",
        "\n",
        "    print(\"\\n‚úÖ Manual testing interface ready for custom inputs!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb02fae-b5b1-48f8-a52c-4c2bf88b09b8",
      "metadata": {
        "id": "abb02fae-b5b1-48f8-a52c-4c2bf88b09b8"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Interactive Testing Function\n",
        "def interactive_test():\n",
        "    \"\"\"Interactive function for manual testing\"\"\"\n",
        "    print(\"üéØ Interactive TKCA Testing\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nOptions:\")\n",
        "        print(\"1. Test existing user from dataset\")\n",
        "        print(\"2. Test with custom keystroke data\")\n",
        "        print(\"3. Exit\")\n",
        "\n",
        "        choice = input(\"\\nEnter your choice (1-3): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            print(f\"\\nAvailable users: {valid_users[:5]}\")  # Show first 5 users\n",
        "            user_id = input(\"Enter user ID to test: \").strip()\n",
        "\n",
        "            if user_id in valid_users:\n",
        "                tester.test_user_sample(user_id)\n",
        "            else:\n",
        "                print(\"‚ùå User not found or insufficient data!\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"\\nüìù Enter custom keystroke data:\")\n",
        "            print(\"Format: key_code,duration_ms,timestamp (one per line)\")\n",
        "            print(\"Enter 'END' when finished (minimum 10 keystrokes needed)\")\n",
        "\n",
        "            custom_data = []\n",
        "            keystroke_count = 0\n",
        "            base_timestamp = 1720000000000000\n",
        "\n",
        "            while True:\n",
        "                line = input(f\"Keystroke {keystroke_count + 1}: \").strip()\n",
        "                if line.upper() == 'END':\n",
        "                    break\n",
        "\n",
        "                try:\n",
        "                    if ',' in line:\n",
        "                        parts = line.split(',')\n",
        "                        key_code = int(parts[0])\n",
        "                        duration = float(parts[1])\n",
        "                        timestamp = int(parts[2]) if len(parts) > 2 else base_timestamp + keystroke_count * 100000\n",
        "                    else:\n",
        "                        # Simple format: just key code\n",
        "                        key_code = int(line)\n",
        "                        duration = np.random.uniform(50, 150)  # Random duration\n",
        "                        timestamp = base_timestamp + keystroke_count * 100000\n",
        "\n",
        "                    custom_data.append([key_code, duration, timestamp])\n",
        "                    keystroke_count += 1\n",
        "\n",
        "                except ValueError:\n",
        "                    print(\"‚ùå Invalid format! Use: key_code,duration_ms,timestamp\")\n",
        "\n",
        "            if len(custom_data) >= 10:\n",
        "                test_user_id = \"custom_user\"\n",
        "                tester.test_user_sample(test_user_id, custom_data)\n",
        "            else:\n",
        "                print(\"‚ùå Need at least 10 keystrokes for testing!\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"üëã Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"‚ùå Invalid choice!\")\n",
        "\n",
        "# Example usage\n",
        "print(\"üìã Example custom keystroke data format:\")\n",
        "print(\"Key codes for common keys:\")\n",
        "print(\"  - A=65, B=66, C=67, ..., Z=90\")\n",
        "print(\"  - 0=48, 1=49, ..., 9=57\")\n",
        "print(\"  - Space=32, Enter=13, Backspace=8\")\n",
        "print(\"\\nüéÆ Ready for interactive testing!\")\n",
        "\n",
        "# Uncomment the line below to start interactive testing\n",
        "interactive_test()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d902d5-c4e8-4458-b5d3-3f0e569e9518",
      "metadata": {
        "id": "d3d902d5-c4e8-4458-b5d3-3f0e569e9518"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Final Performance Evaluation\n",
        "def comprehensive_evaluation(df, valid_users, preprocessor):\n",
        "    \"\"\"Comprehensive evaluation of the TKCA system\"\"\"\n",
        "    print(\"üìä COMPREHENSIVE SYSTEM EVALUATION\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, user in enumerate(valid_users[:3]):  # Test top 3 users\n",
        "        print(f\"\\nüß™ Evaluating model for user {i+1}: {user}\")\n",
        "\n",
        "        # Prepare data\n",
        "        train_loader, val_loader, train_size, val_size = prepare_training_data(\n",
        "            df, user, preprocessor, test_size=0.3\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        model = TKCAModel(num_keys=preprocessor.key_counter)\n",
        "        trainer = TKCATrainer(model)\n",
        "\n",
        "        # Quick training (fewer epochs for evaluation)\n",
        "        _, val_accuracies = trainer.train_model(train_loader, val_loader, num_epochs=20)\n",
        "\n",
        "        final_accuracy = val_accuracies[-1]\n",
        "        results.append({\n",
        "            'user': user,\n",
        "            'accuracy': final_accuracy,\n",
        "            'train_size': train_size,\n",
        "            'val_size': val_size\n",
        "        })\n",
        "\n",
        "        print(f\"   ‚úÖ Final accuracy: {final_accuracy:.2f}%\")\n",
        "\n",
        "    # Summary statistics\n",
        "    accuracies = [r['accuracy'] for r in results]\n",
        "\n",
        "    print(f\"\\nüìà SYSTEM PERFORMANCE SUMMARY\")\n",
        "    print(f\"   Average accuracy: {np.mean(accuracies):.2f}%\")\n",
        "    print(f\"   Best accuracy: {np.max(accuracies):.2f}%\")\n",
        "    print(f\"   Worst accuracy: {np.min(accuracies):.2f}%\")\n",
        "    print(f\"   Standard deviation: {np.std(accuracies):.2f}%\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    users_short = [f\"User {i+1}\" for i in range(len(results))]\n",
        "    plt.bar(users_short, accuracies, color=['green' if acc > 90 else 'orange' if acc > 80 else 'red' for acc in accuracies])\n",
        "    plt.title('TKCA Authentication Accuracy by User')\n",
        "    plt.xlabel('Users')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.ylim(0, 100)\n",
        "\n",
        "    # Add accuracy labels on bars\n",
        "    for i, acc in enumerate(accuracies):\n",
        "        plt.text(i, acc + 1, f'{acc:.1f}%', ha='center')\n",
        "\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "if valid_users and len(valid_users) >= 2:\n",
        "    print(\"üöÄ Starting comprehensive evaluation...\")\n",
        "    eval_results = comprehensive_evaluation(df, valid_users, preprocessor)\n",
        "    print(\"\\n‚úÖ Comprehensive evaluation complete!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Need at least 2 users for comprehensive evaluation\")\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ TKCA KEYSTROKE AUTHENTICATION SYSTEM SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üìä Dataset: {df.shape[0]} keystrokes from {df['user_id'].nunique()} users\")\n",
        "print(f\"üß† Model: Bi-LSTM with attention mechanism\")\n",
        "print(f\"‚öôÔ∏è Features: Key sequences, hold times, digraph times\")\n",
        "print(f\"üéØ Sequence length: {preprocessor.sequence_length}\")\n",
        "print(f\"‚úÖ System ready for deployment!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f768f85-1c32-4d79-b6c9-c95dc68ee115",
      "metadata": {
        "id": "8f768f85-1c32-4d79-b6c9-c95dc68ee115"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cz8c7ORs-Jgk"
      },
      "id": "Cz8c7ORs-Jgk"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F1BEjy0C-Jck"
      },
      "id": "F1BEjy0C-Jck"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "53RoFumA-Ja2"
      },
      "id": "53RoFumA-Ja2"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SikRmJ-Q-JWt"
      },
      "id": "SikRmJ-Q-JWt"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KRQwt6N5-JVV"
      },
      "id": "KRQwt6N5-JVV"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VSFm7wYY-JRt"
      },
      "id": "VSFm7wYY-JRt"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hurlqwCT-JQD"
      },
      "id": "hurlqwCT-JQD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One Shot Learning Model"
      ],
      "metadata": {
        "id": "4g3vmYiF-KaC"
      },
      "id": "4g3vmYiF-KaC"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zQiptP2X-SbE"
      },
      "id": "zQiptP2X-SbE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('keypress_events.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "XJ7XZZD7-NWX",
        "outputId": "28a3515e-a0f6-4f54-dba7-4a2f4192ed33"
      },
      "id": "XJ7XZZD7-NWX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                user_id  id    key_code  key_label  \\\n",
              "0  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429 NaN  4294967304  backspace   \n",
              "1  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429 NaN  4294967304  backspace   \n",
              "2  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429 NaN  4294967304  backspace   \n",
              "3  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429 NaN  4294967304  backspace   \n",
              "4  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429 NaN  4294967304  backspace   \n",
              "\n",
              "   event_type  duration_ms                   timestamp  digram_key1  \\\n",
              "0  individual            2  2025-07-02T13:03:10.033934          NaN   \n",
              "1  individual            1  2025-07-02T13:03:44.809495          NaN   \n",
              "2  individual            2  2025-07-02T13:03:44.971532          NaN   \n",
              "3  individual            1  2025-07-02T13:03:45.117047          NaN   \n",
              "4  individual            0  2025-07-02T13:03:45.243418          NaN   \n",
              "\n",
              "   digram_key2 context_screen  field_name  \n",
              "0          NaN   RegisterPage         NaN  \n",
              "1          NaN      LoginPage         NaN  \n",
              "2          NaN      LoginPage         NaN  \n",
              "3          NaN      LoginPage         NaN  \n",
              "4          NaN      LoginPage         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c48d6452-68cc-4a63-96cf-c65a320a4774\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>id</th>\n",
              "      <th>key_code</th>\n",
              "      <th>key_label</th>\n",
              "      <th>event_type</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>digram_key1</th>\n",
              "      <th>digram_key2</th>\n",
              "      <th>context_screen</th>\n",
              "      <th>field_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>individual</td>\n",
              "      <td>2</td>\n",
              "      <td>2025-07-02T13:03:10.033934</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RegisterPage</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>individual</td>\n",
              "      <td>1</td>\n",
              "      <td>2025-07-02T13:03:44.809495</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LoginPage</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>individual</td>\n",
              "      <td>2</td>\n",
              "      <td>2025-07-02T13:03:44.971532</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LoginPage</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>individual</td>\n",
              "      <td>1</td>\n",
              "      <td>2025-07-02T13:03:45.117047</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LoginPage</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>individual</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-07-02T13:03:45.243418</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LoginPage</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c48d6452-68cc-4a63-96cf-c65a320a4774')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c48d6452-68cc-4a63-96cf-c65a320a4774 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c48d6452-68cc-4a63-96cf-c65a320a4774');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-042a042b-6d6e-476e-b72e-db9eff26de45\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-042a042b-6d6e-476e-b72e-db9eff26de45')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-042a042b-6d6e-476e-b72e-db9eff26de45 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1357,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"bbc7f6a4-53e3-439f-8b99-1ca88483e321\",\n          \"57a06bc3-5dd9-4eab-a0c8-66f71236171e\",\n          \"c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"key_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1191867788,\n        \"min\": 48,\n        \"max\": 4294969871,\n        \"num_unique_values\": 13,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"key_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 21,\n        \"num_unique_values\": 10,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 732,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"digram_key1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"digram_key2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_screen\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_name\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bepzNWKf-vvz"
      },
      "id": "bepzNWKf-vvz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Processing"
      ],
      "metadata": {
        "id": "qf6K2GNwBfxI"
      },
      "id": "qf6K2GNwBfxI"
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df[(df['digram_key1'].isna() | (df['digram_key1'] == '')) &\n",
        "                 (df['digram_key2'].isna() | (df['digram_key2'] == ''))]"
      ],
      "metadata": {
        "id": "q1IRdcCK-kSS"
      },
      "id": "q1IRdcCK-kSS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original rows: {len(df)}\")\n",
        "print(f\"Filtered rows (single-key only): {len(filtered_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LQBMNJk-mFf",
        "outputId": "b65df19d-bfd6-4b3c-9aec-8d7c40120569"
      },
      "id": "1LQBMNJk-mFf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 1357\n",
            "Filtered rows (single-key only): 1357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['event_type'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBvEbeuI-zEv",
        "outputId": "b6dd982c-0823-4826-b129-e73785f5c7ab"
      },
      "id": "qBvEbeuI-zEv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['individual'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['key_label'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrLZD2VV_IHn",
        "outputId": "d84f2a56-d224-41ed-c0da-1ab58b7e1b87"
      },
      "id": "PrLZD2VV_IHn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['backspace', '6', '5', '4', '8', '9', '0', '2', '7', '1', '3',\n",
              "       'enter', 'audio volume down'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['field_name'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvEAPJh8_dRy",
        "outputId": "618bac91-9c5a-45d0-d3bd-7ecdd38ab306"
      },
      "id": "hvEAPJh8_dRy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['id'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8S1RMdc_pfE",
        "outputId": "29becb0f-f5bb-4679-9d8b-70580239e1fa"
      },
      "id": "_8S1RMdc_pfE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0XLTJDm_H62"
      },
      "id": "F0XLTJDm_H62",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns={'digram_key1', 'digram_key2', 'event_type', 'field_name'})"
      ],
      "metadata": {
        "id": "zRcww7nV-67q"
      },
      "id": "zRcww7nV-67q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns={'id'})"
      ],
      "metadata": {
        "id": "-7MTLbSS_oGj"
      },
      "id": "-7MTLbSS_oGj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a8hy84U-_lPb",
        "outputId": "a18ec4ec-0b07-4f9d-9e6e-bda798306df7"
      },
      "id": "a8hy84U-_lPb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                user_id    key_code  key_label  duration_ms  \\\n",
              "0  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429  4294967304  backspace            2   \n",
              "1  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429  4294967304  backspace            1   \n",
              "2  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429  4294967304  backspace            2   \n",
              "3  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429  4294967304  backspace            1   \n",
              "4  c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429  4294967304  backspace            0   \n",
              "\n",
              "                    timestamp context_screen  \n",
              "0  2025-07-02T13:03:10.033934   RegisterPage  \n",
              "1  2025-07-02T13:03:44.809495      LoginPage  \n",
              "2  2025-07-02T13:03:44.971532      LoginPage  \n",
              "3  2025-07-02T13:03:45.117047      LoginPage  \n",
              "4  2025-07-02T13:03:45.243418      LoginPage  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d833dfc-c5f2-4c24-afca-b2a6e186d378\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>key_code</th>\n",
              "      <th>key_label</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>context_screen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>2</td>\n",
              "      <td>2025-07-02T13:03:10.033934</td>\n",
              "      <td>RegisterPage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>1</td>\n",
              "      <td>2025-07-02T13:03:44.809495</td>\n",
              "      <td>LoginPage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>2</td>\n",
              "      <td>2025-07-02T13:03:44.971532</td>\n",
              "      <td>LoginPage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>1</td>\n",
              "      <td>2025-07-02T13:03:45.117047</td>\n",
              "      <td>LoginPage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429</td>\n",
              "      <td>4294967304</td>\n",
              "      <td>backspace</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-07-02T13:03:45.243418</td>\n",
              "      <td>LoginPage</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d833dfc-c5f2-4c24-afca-b2a6e186d378')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d833dfc-c5f2-4c24-afca-b2a6e186d378 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d833dfc-c5f2-4c24-afca-b2a6e186d378');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4f972bb1-dada-42b2-866e-b7bc4a8cb9c3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f972bb1-dada-42b2-866e-b7bc4a8cb9c3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4f972bb1-dada-42b2-866e-b7bc4a8cb9c3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1357,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"bbc7f6a4-53e3-439f-8b99-1ca88483e321\",\n          \"57a06bc3-5dd9-4eab-a0c8-66f71236171e\",\n          \"c9f16bb0-fcb8-43c9-a2fd-c502ce6e5429\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"key_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1191867788,\n        \"min\": 48,\n        \"max\": 4294969871,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          4294967309,\n          49,\n          4294967304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"key_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"enter\",\n          \"1\",\n          \"backspace\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 21,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5,\n          1,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 732,\n        \"samples\": [\n          \"2025-07-04T14:03:35.885838\",\n          \"2025-07-02T15:59:33.561454\",\n          \"2025-07-03T22:19:58.820805\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_screen\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"RegisterPage\",\n          \"LoginPage\",\n          \"add_funds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['key_label'] != 'audio volume down']"
      ],
      "metadata": {
        "id": "AWW6kRdX_wmo"
      },
      "id": "AWW6kRdX_wmo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['key_label'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuE62mtk_7hJ",
        "outputId": "3efc4567-0b93-4509-ccbc-1ee04a4bb1b3"
      },
      "id": "AuE62mtk_7hJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['backspace', '6', '5', '4', '8', '9', '0', '2', '7', '1', '3',\n",
              "       'enter'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['context_screen'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hnpVdXJ_7eZ",
        "outputId": "d97dc0b3-c8c2-4934-a626-b23dcb3dade9"
      },
      "id": "6hnpVdXJ_7eZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['RegisterPage', 'LoginPage', 'transfer_page', 'home', 'pay_bills',\n",
              "       'add_funds'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model creation"
      ],
      "metadata": {
        "id": "v_HRgYgYBdnr"
      },
      "id": "v_HRgYgYBdnr"
    },
    {
      "cell_type": "code",
      "source": [
        "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "df = df.sort_values(['user_id', 'timestamp'])"
      ],
      "metadata": {
        "id": "PUWZIH4CAb5P"
      },
      "id": "PUWZIH4CAb5P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW0qjctbBqu6",
        "outputId": "c542c3c2-1df9-4de9-aa07-0881780df55a"
      },
      "id": "rW0qjctbBqu6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1355 entries, 1038 to 995\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   user_id         1355 non-null   object        \n",
            " 1   key_code        1355 non-null   int64         \n",
            " 2   key_label       1355 non-null   object        \n",
            " 3   duration_ms     1355 non-null   int64         \n",
            " 4   timestamp       1355 non-null   datetime64[ns]\n",
            " 5   context_screen  1355 non-null   object        \n",
            "dtypes: datetime64[ns](1), int64(2), object(3)\n",
            "memory usage: 74.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['inter_key_time'] = df.groupby('user_id')['timestamp'].diff().dt.total_seconds().fillna(0)"
      ],
      "metadata": {
        "id": "MWptHnOmBks3"
      },
      "id": "MWptHnOmBks3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "sr-XaIUOB_i1"
      },
      "id": "sr-XaIUOB_i1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['key_label_encoded'] = le.fit_transform(df['key_label'])"
      ],
      "metadata": {
        "id": "arbuCyyZB4fD"
      },
      "id": "arbuCyyZB4fD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['key_label_encoded', 'duration_ms', 'inter_key_time']"
      ],
      "metadata": {
        "id": "1m6UPRlUCEcE"
      },
      "id": "1m6UPRlUCEcE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset"
      ],
      "metadata": {
        "id": "npHtpD5rCHmR"
      },
      "id": "npHtpD5rCHmR"
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "-MRvAncXFFA-"
      },
      "id": "-MRvAncXFFA-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "DWqKDuZuD1uO"
      },
      "id": "DWqKDuZuD1uO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class KeystrokeSequenceDataset(Dataset):\n",
        "    def __init__(self, user_sequences, n_pairs=1000):\n",
        "        self.pairs = []\n",
        "        self.labels = []\n",
        "\n",
        "        users = list(user_sequences.keys())\n",
        "        for _ in range(n_pairs):\n",
        "            # Positive pair (same user)\n",
        "            user = random.choice(users)\n",
        "            seqs = user_sequences[user]\n",
        "            if len(seqs) >= 2:\n",
        "                a, b = random.sample(seqs, 2)\n",
        "                self.pairs.append((a, b))\n",
        "                self.labels.append(1)\n",
        "\n",
        "            # Negative pair (different users)\n",
        "            u1, u2 = random.sample(users, 2)\n",
        "            seq1 = random.choice(user_sequences[u1])\n",
        "            seq2 = random.choice(user_sequences[u2])\n",
        "            self.pairs.append((seq1, seq2))\n",
        "            self.labels.append(0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq1, seq2 = self.pairs[idx]\n",
        "        return (\n",
        "            torch.tensor(seq1, dtype=torch.float32),\n",
        "            torch.tensor(seq2, dtype=torch.float32),\n",
        "            torch.tensor(self.labels[idx], dtype=torch.float32),\n",
        "        )\n"
      ],
      "metadata": {
        "id": "ZglDE-IZCFd1"
      },
      "id": "ZglDE-IZCFd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Siamese GRU"
      ],
      "metadata": {
        "id": "vKwXbsm7D7AG"
      },
      "id": "vKwXbsm7D7AG"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "LJ9VQjpsEOFv"
      },
      "id": "LJ9VQjpsEOFv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SiameseGRU(nn.Module):\n",
        "    def __init__(self, input_dim=3, hidden_dim=64):\n",
        "        super(SiameseGRU, self).__init__()\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        _, h = self.gru(x)  # h: (1, batch, hidden)\n",
        "        return h.squeeze(0)  # (batch, hidden)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "      out1 = self.forward_once(x1)\n",
        "      out2 = self.forward_once(x2)\n",
        "      diff = torch.abs(out1 - out2)       # [batch, hidden_dim]\n",
        "      return self.fc(diff)                # Now input is [batch, hidden_dim]\n"
      ],
      "metadata": {
        "id": "qgOp2rn2D4Ax"
      },
      "id": "qgOp2rn2D4Ax",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x1, x2, y in dataloader:\n",
        "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x1, x2).squeeze()\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "fZsPxvR4D_RH"
      },
      "id": "fZsPxvR4D_RH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "seq_len = 20\n",
        "user_sequences = {}\n",
        "for user_id, group in df.groupby(\"user_id\"):\n",
        "    sequences = []\n",
        "    arr = group[features].values\n",
        "    for i in range(0, len(arr) - seq_len, seq_len):\n",
        "        sequences.append(arr[i:i+seq_len])\n",
        "    if len(sequences) >= 2:\n",
        "        user_sequences[user_id] = sequences\n",
        "\n",
        "dataset = KeystrokeSequenceDataset(user_sequences, n_pairs=2000)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SiameseGRU().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss = train(model, dataloader, optimizer, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI0oIWr_EGdD",
        "outputId": "ddf9afed-6f41-4748-cf25-5cd9067dffe9"
      },
      "id": "NI0oIWr_EGdD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5254\n",
            "Epoch 2, Loss: 0.2101\n",
            "Epoch 3, Loss: 0.0361\n",
            "Epoch 4, Loss: 0.0051\n",
            "Epoch 5, Loss: 0.0024\n",
            "Epoch 6, Loss: 0.0015\n",
            "Epoch 7, Loss: 0.0010\n",
            "Epoch 8, Loss: 0.0007\n",
            "Epoch 9, Loss: 0.0006\n",
            "Epoch 10, Loss: 0.0004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"siamese_gru_model.pth\")\n",
        "print(\"‚úÖ Model weights saved as siamese_gru_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6GhEQ_CVnm0",
        "outputId": "600cb365-5e94-4381-8bb6-3aadfb2f8f9e"
      },
      "id": "O6GhEQ_CVnm0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model weights saved as siamese_gru_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "K8p4fVOcGJ1v"
      },
      "id": "K8p4fVOcGJ1v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = list(user_sequences.keys())\n",
        "print(user_ids)\n",
        "user_real = user_ids[0]\n",
        "user_imposter = user_ids[1]\n",
        "\n",
        "real_sequences = user_sequences[user_real]\n",
        "imposter_sequences = user_sequences[user_imposter]\n",
        "\n",
        "reference_seq = real_sequences[0]\n",
        "\n",
        "same_user_seq = real_sequences[1]\n",
        "different_user_seq = imposter_sequences[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuYPuGTPGGeY",
        "outputId": "3b36ed77-55e5-4cca-f089-97a6926388bc"
      },
      "id": "ZuYPuGTPGGeY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['235fc56c-8c60-43a1-a552-a2d95b3e5743', 'bbc7f6a4-53e3-439f-8b99-1ca88483e321', 'f8e0e899-10aa-41dd-8be4-367bf324bfeb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def get_embedding(model, sequence, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        sequence = torch.tensor(sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        embedding = model.forward_once(sequence)\n",
        "    return embedding.cpu().numpy().flatten()\n",
        "\n",
        "def similarity_score(emb1, emb2):\n",
        "    return 1 - cosine(emb1, emb2)  # Higher = more similar\n"
      ],
      "metadata": {
        "id": "4xE_CcxtGfcO"
      },
      "id": "4xE_CcxtGfcO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embeddings\n",
        "ref_emb = get_embedding(model, reference_seq, device)\n",
        "same_emb = get_embedding(model, same_user_seq, device)\n",
        "diff_emb = get_embedding(model, different_user_seq, device)\n",
        "\n",
        "# Compare\n",
        "score_same = similarity_score(ref_emb, same_emb)\n",
        "score_diff = similarity_score(ref_emb, diff_emb)\n",
        "\n",
        "print(f'User is : {user_real}')\n",
        "print(f'Imposter is : {user_imposter}')\n",
        "print(f\"Similarity (same user): {score_same:.4f}\")\n",
        "print(f\"Similarity (imposter): {score_diff:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AflcLhN2GhYd",
        "outputId": "faf95e45-b430-4259-ba80-51c0b960f12d"
      },
      "id": "AflcLhN2GhYd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User is : 235fc56c-8c60-43a1-a552-a2d95b3e5743\n",
            "Imposter is : bbc7f6a4-53e3-439f-8b99-1ca88483e321\n",
            "Similarity (same user): 0.6846\n",
            "Similarity (imposter): 0.0349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Based Implementation"
      ],
      "metadata": {
        "id": "q63jojCLPZMT"
      },
      "id": "q63jojCLPZMT"
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 20\n",
        "FEATURES = ['key_label_encoded', 'duration_ms', 'inter_key_time']"
      ],
      "metadata": {
        "id": "1-mOEencPbck"
      },
      "id": "1-mOEencPbck",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_sequences = {}\n",
        "for user_id, group in df.sort_values(['user_id','timestamp']).groupby('user_id'):\n",
        "    arr = group[FEATURES].values\n",
        "    seqs = [arr[i:i+SEQ_LEN] for i in range(0, len(arr) - SEQ_LEN + 1, SEQ_LEN)]\n",
        "    if len(seqs) >= 2:\n",
        "        user_sequences[user_id] = seqs"
      ],
      "metadata": {
        "id": "pCRTV9gYPctn"
      },
      "id": "pCRTV9gYPctn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(user_seqs, n_pairs=2000):\n",
        "    users = list(user_seqs.keys())\n",
        "    X1, X2, y = [], [], []\n",
        "    for _ in range(n_pairs):\n",
        "        # positive pair\n",
        "        u = random.choice(users)\n",
        "        a, b = random.sample(user_seqs[u], 2)\n",
        "        X1.append(a); X2.append(b); y.append(1.0)\n",
        "\n",
        "        # negative pair\n",
        "        u1, u2 = random.sample(users, 2)\n",
        "        X1.append(random.choice(user_seqs[u1]))\n",
        "        X2.append(random.choice(user_seqs[u2]))\n",
        "        y.append(0.0)\n",
        "\n",
        "    return np.array(X1), np.array(X2), np.array(y, dtype='float32')\n"
      ],
      "metadata": {
        "id": "LX4HdgZ9Ph-F"
      },
      "id": "LX4HdgZ9Ph-F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "w3kkKae6Rx5A"
      },
      "id": "w3kkKae6Rx5A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1, X2, y = make_pairs(user_sequences, n_pairs=2000)\n",
        "X1_tr, X1_va, X2_tr, X2_va, y_tr, y_va = train_test_split(\n",
        "    X1, X2, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "T4NA06FzRgIB"
      },
      "id": "T4NA06FzRgIB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_siamese_gru(input_shape=(SEQ_LEN, len(FEATURES)), hidden_dim=64):\n",
        "    seq_in = Input(shape=input_shape)\n",
        "    x = layers.GRU(hidden_dim)(seq_in)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    shared = Model(seq_in, x, name='shared_gru')\n",
        "\n",
        "    a = Input(shape=input_shape)\n",
        "    b = Input(shape=input_shape)\n",
        "    da = shared(a)\n",
        "    db = shared(b)\n",
        "    diff = layers.Lambda(lambda t: tf.abs(t[0] - t[1]))([da, db])\n",
        "    out = layers.Dense(1, activation='sigmoid')(diff)\n",
        "    return Model([a, b], out)\n",
        "\n",
        "model = build_siamese_gru()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "VXx--iTyR1iD",
        "outputId": "eafdcb74-f7be-4577-930a-415f464aa022"
      },
      "id": "VXx--iTyR1iD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_10      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m3\u001b[0m)     ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ input_layer_11      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m3\u001b[0m)     ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ shared_gru          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        ‚îÇ     \u001b[38;5;34m15,328\u001b[0m ‚îÇ input_layer_10[\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mFunctional\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ input_layer_11[\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ shared_gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ shared_gru[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_7 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         ‚îÇ         \u001b[38;5;34m33\u001b[0m ‚îÇ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_10      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ input_layer_11      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ shared_gru          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,328</span> ‚îÇ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        ‚îÇ                   ‚îÇ            ‚îÇ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ shared_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ shared_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> ‚îÇ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,361\u001b[0m (60.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,361</span> (60.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,361\u001b[0m (60.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,361</span> (60.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    [X1_tr, X2_tr], y_tr,\n",
        "    validation_data=([X1_va, X2_va], y_va),\n",
        "    batch_size=32, epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEXS_cQTR4o_",
        "outputId": "c0f0d4b5-c49f-4ed1-e5fe-1c864177a178"
      },
      "id": "sEXS_cQTR4o_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6740 - loss: 0.6034 - val_accuracy: 0.8037 - val_loss: 0.4100\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8596 - loss: 0.3446 - val_accuracy: 0.9525 - val_loss: 0.1970\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9761 - loss: 0.1445 - val_accuracy: 1.0000 - val_loss: 0.0576\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0459 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9934 - loss: 0.0267 - val_accuracy: 0.9563 - val_loss: 0.1153\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9807 - loss: 0.0711 - val_accuracy: 1.0000 - val_loss: 0.0176\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0109\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78a207596810>"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = model.get_layer('shared_gru')\n",
        "\n",
        "def get_emb(seq):\n",
        "    return embedder.predict(seq[np.newaxis], verbose=0)[0]\n"
      ],
      "metadata": {
        "id": "bGkZpHapR7O7"
      },
      "id": "bGkZpHapR7O7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uids = list(user_sequences)\n",
        "print(uids[0])\n",
        "print(uids[1])\n",
        "ref_seq  = user_sequences[uids[1]][0]\n",
        "same_seq = user_sequences[uids[1]][1]\n",
        "imp_seq  = user_sequences[uids[0]][0]\n",
        "\n",
        "e_ref  = get_emb(ref_seq)\n",
        "e_same = get_emb(same_seq)\n",
        "e_imp  = get_emb(imp_seq)\n",
        "\n",
        "print(f\"Cosine sim (same):  {1 - cosine(e_ref, e_same):.4f}\")\n",
        "print(f\"Cosine sim (imp) :  {1 - cosine(e_ref, e_imp):.4f}\")\n",
        "print(f\"Euclid dist (same): {euclidean(e_ref, e_same):.4f}\")\n",
        "print(f\"Euclid dist (imp) : {euclidean(e_ref, e_imp):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Roa3oALSlpf",
        "outputId": "0a1d3fad-a739-4b5d-cb49-e1356e8437e0"
      },
      "id": "5Roa3oALSlpf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235fc56c-8c60-43a1-a552-a2d95b3e5743\n",
            "bbc7f6a4-53e3-439f-8b99-1ca88483e321\n",
            "Cosine sim (same):  0.9608\n",
            "Cosine sim (imp) :  0.1925\n",
            "Euclid dist (same): 3.2264\n",
            "Euclid dist (imp) : 15.2448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Z1dHQYq8VcJV"
      },
      "id": "Z1dHQYq8VcJV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"siamese_model.keras\")"
      ],
      "metadata": {
        "id": "i0cLWYrYVbRL"
      },
      "id": "i0cLWYrYVbRL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.experimental_enable_resource_variables = True\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"siamese_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"‚úÖ TFLite model saved with resource variable support.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "fGRbbEzmVYTI",
        "outputId": "d65f15bc-503c-4f47-c821-f181173070cc"
      },
      "id": "fGRbbEzmVYTI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpr0j62qj5'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 20, 3), dtype=tf.float32, name='keras_tensor_39'), TensorSpec(shape=(None, 20, 3), dtype=tf.float32, name='keras_tensor_40')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132635610724304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132635615401680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132635615401872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132635610720848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132635610725840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132635610725072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132635610726032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "Variable constant folding is failed. Please consider using enabling `experimental_enable_resource_variables` flag in the TFLite converter object. For example, converter.experimental_enable_resource_variables = True<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_3_1/shared_gru_1/gru_3_1/TensorArrayV2_1@__inference_function_45381\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_45422\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_3_1/shared_gru_1/gru_3_1/TensorArrayV2_1@__inference_function_45381\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_45422\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-196-175718984.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_enable_resource_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"siamese_model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1239\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \"\"\"\n\u001b[0;32m-> 1754\u001b[0;31m     \u001b[0msaved_model_convert_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_as_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1733\u001b[0m       )\n\u001b[1;32m   1734\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m         return super(TFLiteKerasModelConverterV2, self).convert(\n\u001b[0m\u001b[1;32m   1736\u001b[0m             \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[0;31m# Converts model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m     result = _convert_graphdef(\n\u001b[0m\u001b[1;32m   1474\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert_graphdef\u001b[0;34m(input_data, input_tensors, output_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m   data = convert(\n\u001b[0m\u001b[1;32m   1029\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m       \u001b[0mconversion_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model_flags, conversion_flags, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    374\u001b[0m               \u001b[0menable_mlir_converter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m           )\n\u001b[0;32m--> 376\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m   return _run_deprecated_conversion_binary(\n",
            "\u001b[0;31mConverterError\u001b[0m: Variable constant folding is failed. Please consider using enabling `experimental_enable_resource_variables` flag in the TFLite converter object. For example, converter.experimental_enable_resource_variables = True<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_3_1/shared_gru_1/gru_3_1/TensorArrayV2_1@__inference_function_45381\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_45422\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_3_1/shared_gru_1/gru_3_1/TensorArrayV2_1@__inference_function_45381\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_45422\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}